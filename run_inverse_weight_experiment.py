#!/usr/bin/env python3
"""
Experiment to prove BIT's weighted loss mechanism drives improvement.

This script runs 3 configurations:
1. w=2.0 (Full BIT) - upweight benign-trigger samples
2. w=1.0 (Uniform weights) - no weighting
3. w=0.5 (Inverse weights) - DOWNweight benign-trigger samples

If improvement was just from "adding benign-trigger samples", all 3 would perform similarly.
The fact that w=2.0 > w=1.0 > w=0.5 proves the weighting MECHANISM matters.
"""

import sys
import json
from pathlib import Path
from typing import List, Tuple, Dict
import random
from collections import Counter
import numpy as np
from sklearn.metrics import classification_report, precision_recall_curve

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from detection.embedding_classifier import EmbeddingClassifier
from datasets import load_dataset

# Import data loading functions from train_bit_model.py
from train_bit_model import (
    load_satml_dataset,
    load_deepset_dataset,
    load_notinject_dataset,
    generate_synthetic_benign_triggers,
    TRIGGER_WORDS,
)


def prepare_bit_dataset_with_weight(
    target_total: int = 5000,
    benign_trigger_weight: float = 2.0,
) -> Tuple[List[str], List[int], List[float]]:
    """
    Prepare BIT dataset with specified benign-trigger weight.

    Args:
        target_total: Total training samples
        benign_trigger_weight: Weight for benign-trigger samples (2.0, 1.0, or 0.5)

    Returns:
        texts, labels, weights
    """
    print(f"\n{'='*60}")
    print(f"Preparing BIT dataset with w={benign_trigger_weight}")
    print(f"{'='*60}")

    # Load datasets
    satml_inj, satml_safe = load_satml_dataset()
    deepset_inj, deepset_safe = load_deepset_dataset()
    notinject_safe = load_notinject_dataset()

    # Combine datasets
    all_injections = satml_inj + deepset_inj
    all_safe = satml_safe + deepset_safe + notinject_safe

    # Generate benign-trigger samples
    synthetic_bt = generate_synthetic_benign_triggers(n_samples=2000)

    # Tag sample types
    injections = [{"text": t, "label": 1, "type": "injection"} for t in all_injections]
    safe = [{"text": t, "label": 0, "type": "safe"} for t in all_safe]
    benign_triggers = [{"text": t, "label": 0, "type": "benign_trigger"} for t in synthetic_bt]

    # BIT composition: 40% injection, 40% safe, 20% benign-trigger
    n_injection = int(target_total * 0.4)
    n_safe = int(target_total * 0.4)
    n_benign_trigger = int(target_total * 0.2)

    print(f"\nTarget composition:")
    print(f"  Injections: {n_injection} (40%)")
    print(f"  Safe: {n_safe} (40%)")
    print(f"  Benign-trigger: {n_benign_trigger} (20%)")

    # Sample from each category
    balanced = []
    balanced.extend(random.sample(injections, min(n_injection, len(injections))))
    balanced.extend(random.sample(safe, min(n_safe, len(safe))))
    balanced.extend(random.sample(benign_triggers, min(n_benign_trigger, len(benign_triggers))))

    random.shuffle(balanced)

    # Extract texts, labels, and weights
    texts = [s["text"] for s in balanced]
    labels = [s["label"] for s in balanced]
    weights = [benign_trigger_weight if s["type"] == "benign_trigger" else 1.0 for s in balanced]

    # Report final composition
    final_types = [s["type"] for s in balanced]
    composition = Counter(final_types)

    print(f"\nâœ… Final composition ({len(balanced)} samples):")
    for sample_type, count in composition.items():
        pct = 100 * count / len(balanced)
        weight_info = f"w={benign_trigger_weight}" if sample_type == "benign_trigger" else "w=1.0"
        print(f"   {sample_type}: {count} ({pct:.1f}%) [{weight_info}]")

    return texts, labels, weights


def optimize_threshold(classifier, X_val: List[str], y_val: List[int], target_recall: float = 0.98) -> float:
    """Optimize classification threshold for target recall."""
    print(f"\nðŸŽ¯ Optimizing threshold for {target_recall*100:.0f}% recall...")

    # Get probability predictions
    probs = classifier.predict_proba(X_val)
    if probs.ndim == 2:
        probs = probs[:, 1]

    # Calculate precision-recall curve
    precisions, recalls, thresholds = precision_recall_curve(y_val, probs)

    # Find threshold that achieves target recall
    valid_idx = recalls[:-1] >= target_recall
    if not any(valid_idx):
        print(f"âš ï¸  Cannot achieve {target_recall*100}% recall!")
        optimal_threshold = 0.5
    else:
        valid_thresholds = thresholds[valid_idx]
        optimal_threshold = float(np.max(valid_thresholds))

    print(f"âœ… Optimal threshold: {optimal_threshold:.4f}")
    return optimal_threshold


def evaluate_on_notinject(classifier, threshold: float) -> Dict:
    """Evaluate on NotInject test set."""
    print("\nðŸ“Š Evaluating on NotInject test set...")

    # Load NotInject test set
    dataset = load_dataset("deepset/prompt-injections", split="test")

    texts = []
    labels = []

    for example in dataset:
        texts.append(example["text"])
        # Label 1 = injection, 0 = safe
        labels.append(1 if example["label"] == 1 else 0)

    # Predict
    probs = classifier.predict_proba(texts)
    if probs.ndim == 2:
        probs = probs[:, 1]

    predictions = (probs >= threshold).astype(int)

    # Calculate metrics
    from sklearn.metrics import classification_report, confusion_matrix

    report = classification_report(labels, predictions, output_dict=True, zero_division=0)
    cm = confusion_matrix(labels, predictions)

    # Calculate FPR on safe samples (label=0)
    safe_mask = np.array(labels) == 0
    safe_predictions = predictions[safe_mask]
    fpr = np.mean(safe_predictions) if len(safe_predictions) > 0 else 0.0

    # Calculate recall on injection samples (label=1)
    inj_mask = np.array(labels) == 1
    inj_predictions = predictions[inj_mask]
    recall = np.mean(inj_predictions) if len(inj_predictions) > 0 else 0.0

    print(f"\nâœ… NotInject Results:")
    print(f"   False Positive Rate: {fpr*100:.1f}%")
    print(f"   Attack Recall: {recall*100:.1f}%")
    print(f"   Overall F1: {report['weighted avg']['f1-score']*100:.1f}%")

    return {
        "fpr": fpr,
        "recall": recall,
        "f1": report['weighted avg']['f1-score'],
        "report": report,
    }


def run_experiment(weight: float) -> Dict:
    """Run single experiment with specified weight."""
    print(f"\n{'#'*60}")
    print(f"# EXPERIMENT: Benign-Trigger Weight = {weight}")
    print(f"{'#'*60}")

    # Prepare dataset
    X_train, y_train, weights = prepare_bit_dataset_with_weight(
        target_total=5000,
        benign_trigger_weight=weight,
    )

    # Split for validation (80/20)
    split_idx = int(len(X_train) * 0.8)
    X_train_split = X_train[:split_idx]
    y_train_split = y_train[:split_idx]
    weights_split = weights[:split_idx]

    X_val = X_train[split_idx:]
    y_val = y_train[split_idx:]

    print(f"\nðŸ“Š Train/Val split:")
    print(f"   Training: {len(X_train_split)} samples")
    print(f"   Validation: {len(X_val)} samples")

    # Train classifier
    print(f"\nðŸš€ Training XGBoost with MiniLM embeddings...")
    classifier = EmbeddingClassifier(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        use_xgboost=True,
    )

    classifier.train_on_dataset(
        X_train_split,
        y_train_split,
        sample_weights=weights_split,
    )

    # Optimize threshold
    threshold = optimize_threshold(classifier, X_val, y_val, target_recall=0.98)
    classifier.set_threshold(threshold)

    # Evaluate on NotInject
    results = evaluate_on_notinject(classifier, threshold)
    results["weight"] = weight
    results["threshold"] = threshold

    return results


def main():
    """Run all 3 weight experiments."""
    random.seed(42)
    np.random.seed(42)

    print("="*60)
    print("BIT WEIGHTED LOSS MECHANISM PROOF")
    print("="*60)
    print("\nThis experiment proves that weighted loss drives improvement,")
    print("not just the presence of benign-trigger samples.")
    print("\nWe test 3 configurations on IDENTICAL data (40/40/20 split):")
    print("  1. w=2.0 (Full BIT) - upweight benign-trigger samples")
    print("  2. w=1.0 (Uniform)  - no weighting")
    print("  3. w=0.5 (Inverse)  - DOWNweight benign-trigger samples")
    print("\nIf the 40/40/20 data split was sufficient, all would perform equally.")
    print("If weighting matters, we expect: w=2.0 > w=1.0 > w=0.5")
    print("="*60)

    weights_to_test = [2.0, 1.0, 0.5]
    results = {}

    for weight in weights_to_test:
        results[weight] = run_experiment(weight)

    # Print summary
    print("\n" + "="*60)
    print("SUMMARY: Weight vs Performance")
    print("="*60)
    print(f"\n{'Weight':<10} {'NotInject FPR':<15} {'Attack Recall':<15} {'Overall F1':<12}")
    print("-" * 60)

    for weight in weights_to_test:
        r = results[weight]
        print(f"{weight:<10.1f} {r['fpr']*100:<14.1f}% {r['recall']*100:<14.1f}% {r['f1']*100:<11.1f}%")

    # Check monotonicity
    print("\n" + "="*60)
    print("HYPOTHESIS TEST: Does weighting direction matter?")
    print("="*60)

    fpr_2_0 = results[2.0]['fpr']
    fpr_1_0 = results[1.0]['fpr']
    fpr_0_5 = results[0.5]['fpr']

    monotonic = fpr_2_0 < fpr_1_0 < fpr_0_5

    print(f"\nFPR ordering: {fpr_2_0:.1%} (w=2.0) < {fpr_1_0:.1%} (w=1.0) < {fpr_0_5:.1%} (w=0.5)")

    if monotonic:
        print("âœ… HYPOTHESIS CONFIRMED: Weighting direction matters!")
        print("   â†’ This proves it's the MECHANISM, not just data composition")
    else:
        print("âš ï¸  HYPOTHESIS NOT CONFIRMED: Results not monotonic")

    print(f"\nImprovement from w=1.0 to w=2.0: {(fpr_1_0 - fpr_2_0)*100:.1f} pp")
    print(f"Degradation from w=1.0 to w=0.5: {(fpr_0_5 - fpr_1_0)*100:.1f} pp")

    # Save results
    output_file = Path("results/inverse_weight_experiment.json")
    output_file.parent.mkdir(exist_ok=True)

    with open(output_file, 'w') as f:
        # Convert to serializable format
        serializable_results = {}
        for weight, r in results.items():
            serializable_results[str(weight)] = {
                "weight": r["weight"],
                "fpr": r["fpr"],
                "recall": r["recall"],
                "f1": r["f1"],
                "threshold": r["threshold"],
            }
        json.dump(serializable_results, f, indent=2)

    print(f"\nðŸ’¾ Results saved to: {output_file}")

    # Generate LaTeX table row
    print("\n" + "="*60)
    print("LATEX TABLE ROW (for Table 8):")
    print("="*60)
    r = results[0.5]
    print(f"Inverse Weight ($w=0.5$) & {r['fpr']*100:.1f}\\% & {r['recall']*100:.1f}\\% & {r['f1']*100:.1f}\\% \\\\")


if __name__ == "__main__":
    main()
